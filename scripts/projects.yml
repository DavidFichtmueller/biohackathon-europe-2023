---
modified_date: 2022-05-25
project_list:
- abstract: "Ontologies are widely used to make biological knowledge FAIR. There are\
    \ many examples of ontologies and data standards used across the different ELIXIR\
    \ communities, such as MONDO, used to harmonise knowledge about diseases; the\
    \ Experimental Factor Ontology (EFO) and the Human Cell Atlas ontology (HCAO),\
    \ application ontologies used to integrate data from biomedical studies; and the\
    \ SBOL standard used by the microbial biotechnology community.\n\nA major challenge\
    \ in the application of ontologies is that their formal terminology does not always\
    \ match the language in common use by practitioners. This is problematic for two\
    \ reasons: (1) when curating data (e.g. from studies), text strings are often\
    \ different from the ontology terms to which they must be mapped; and (2) knowledge\
    \ described using ontology terms does not always match the terminology in common\
    \ use.\n\nTools to address (1) include ZOOMA and OntoString developed at EMBL-EBI\
    \ for the Human Cell Atlas Data Coordination Platform and EOSCLife, which use\
    \ existing manually curated mappings to automatically suggest mappings for future\
    \ strings. However, (2) is less explored. Some ontologies, such as the Human Phenotype\
    \ Ontology (HPO), are beginning to provide \u201Clayperson\u201D synonyms for\
    \ terms. However, this approach is not standardised, and lacks support in ontology\
    \ tooling including the Ontology Lookup Service (OLS).\n\nIn this proposal, we\
    \ aim to explore this problem from two different perspectives. First, we will\
    \ implement support in OLS for alternate terminologies, and the ability to choose\
    \ which subset of synonyms to display in the website and API. Secondly, we will\
    \ demonstrate the applicability of this new functionality in the Microbial Biotechnology\
    \ ELIXIR community, which does not yet have an ontology for common end-user terminology.\
    \ We will therefore disseminate ontology best practices from the biomedical community\
    \ to add a MB application ontology, with mappings to alternate terminologies,\
    \ to the OLS."
  authors: Duygu Dede Sener, Duncan Ng, Federico Bernuzzi, Giovanni Bacci and Jan
    Stanstrup
  expected_audience: 'We invite participants in the knowledge of:

    FAIR (Findable, Accessible, Interoperable, Reusable) data principles

    Ontology

    Resource/database specific knowledge'
  expected_outcomes: The infrastructure for alignment of existing data, repositories,
    tools and services
  hacking_topic: 'Data Platform

    Federated Human Data

    Interoperability Platform

    Metabolomics

    Tools Platform'
  leads: 'Duygu Dede Sener

    d.dedesener@maastrichtuniversity.nl'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/1
  number: '1'
  number_of_expected_hacking_days: '2'
  project_number: 1
  title: Alignment of food and nutrition study data
- abstract: "The contribution and effort of biocurators is extremely difficult to\
    \ attribute and quantify. APICURON (https://apicuron.org) is a web server that\
    \ provides biological databases and organizations with a real-time automatic tracking\
    \ system of biocuration activities. Registered resources submit biocuration events\
    \ and the APICURON web server calculates achievements (medals, badges) and leaderboards\
    \ on the fly. Results are stored and served through a public API and the APICURON\
    \ website. APICURON aims at promoting engagement and certifying biocuration CVs,\
    \ to this end it is already connected with ORCID to automatically propagate badges\
    \ and achievements to ORCID user profiles.\nAPICURON database schema is extremely\
    \ simple and lightweight, however, member databases that want to push data, need\
    \ to generate metadata representing curation activities periodically and in a\
    \ well defined JSON document. This entails member databases being able to: i)\
    \ compare different versions of a curated entry; ii) retrieve the curator ORCID;\
    \ iii) reliably assign a timestamp; and iv) schedule automatic execution of the\
    \ submission task, including authentication and interaction with the APICURON\
    \ API. Each of these points can be problematic for different reasons, in particular\
    \ for those databases not properly implementing versioning. Also, when comparing\
    \ different versions of the same entry it is necessary to identify changes associated\
    \ with curation activity and map those changes to a standard vocabulary.\nAPICURON\
    \ is already supported by 2022-APICURON implementation study of the Data Platform\
    \ and well connected with the International Society for Biocuration. A core of\
    \ early adopters\u2019 curation databases (DisProt, PED, Pfam, Rfam, IntAct, SABIO-RK,\
    \ Reactome, PomBase, SILVA, BioModels) are already connecting to APICURON. This\
    \ biohackathon will focus on the implementation and testing of software pipelines\
    \ for the extraction and submission of curation metadata to APICURON. The effort\
    \ will be used to revise the relevant documentation in order to simplify integration\
    \ of other databases."
  authors: Damiano Piovesan and Silvio Tosatto
  expected_audience: Database maintainers with knowledge about versioning, interaction
    with API, authentication technology
  expected_outcomes: "Biohackathon outcomes\n- Report about versioning strategies\
    \ in curation databases \n- Workflows for the extraction of curation activities.\
    \ One for each participating database\n- Server client (software) to test metadata\
    \ submission to APICURON \n- Guidelines about how to connect a curation resource\
    \ to APICURON\n\nLong term outcomes\n- \u201CSandbox\u201D APICURON server for\
    \ testing purposes (3 months)\n- Integration of database versioning strategies\
    \ into APICURON guidelines (6 months)\n- New curation databases automatically\
    \ pushing data into APICURON (12 months)\n- Definition of an ontology for curation\
    \ activities, and/or extention of the Contributor Role Ontology (12 months)"
  hacking_topic: 'Data Platform

    Interoperability Platform

    Tools Platform'
  leads: Damiano Piovesan, damiano.piovesan@unipd.it
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/2
  number: '2'
  number_of_expected_hacking_days: '4'
  project_number: 2
  title: APICURON integration with curation databases
- abstract: 'The project consists in designing a five-day training school in Bioinformatics,
    tailored to each of three different target groups of young students. Additionally,
    a practical example of a real training school will be presented as a use case.


    The envisaged training schools will be designed as five-day-long introductory
    courses in Bioinformatics, with a focus on protein sequence and structure. We
    identified three target groups that will have a dedicated training school according
    to their background: 1) high school students; 2) undergraduate students in Biology
    or related degrees; 3) bachelor students in Computer Science. During the biohackathon,
    we will determine the learning goals and learning objectives of each specific
    target group. Moreover, we will highlight what an ideal program should contain
    and we will define the associated activity and assessment plans. An ideal training
    school should present overviews of Erasmus+ mobility opportunities and FAIR principles
    (especially for undergraduate students), but also raise awareness of biodiversity
    loss and gender inequality in science.


    The ELIXIR Training Platform will be used as a material source for the training
    schools'' content creation. We also aim to actively contribute to the expansion
    of the platform during the biohackathon and afterwards. In particular, we will
    generate open-source and FAIRifyed teaching content and materials.


    The authors of this proposal founded NGO ''Bioinformatika'', which offers freely-available
    training schools in Bioinformatics to young students. The NGO aims to compensate
    for the fact that Bioinformatics is only rarely integrated into high school teaching
    programs and to play an active role in preparing the next generation of bioinformaticians.
    We operated mostly in Montenegro and with high school students. We consider the
    Elixir Biohackathon as an opportunity to expand the format in Europe, improve
    the contents of the training schools and increase our collaboration network with
    other researchers involved in training and education.'
  authors: Marco Anteghini and Katarina Elez
  expected_audience: '- Researchers with an interest in training and education.

    - Researchers with Bioinformatics background.

    - Researchers with Biology-related backgrounds.

    - Researchers with Computer Science background.'
  expected_outcomes: '- Creation of three teaching plans in terms of learning goals
    and learning objectives for introductory training schools in Bioinformatics. The
    target groups will be: 1) high school students; 2) undergraduate students in Biology
    or related degrees; 3) bachelor students in Computer Science. Timeframe: 2 hacking
    days


    - Preparation of a five-day training school course content that will be open-source
    and FAIRifyed. The training school preparation will be chosen among the three
    target groups. Timeframe: 2 hacking days


    - Preparation of five-day course content for the remaining two training schools.
    Materials will be open-source and FAIRifyed. The material will be available through
    the Elixir training platform. Timeframe: 3 months after the biohackathon.


    - Writing a bioinformatics training school handbook for the chosen use case which
    will be available on BioHackrXiv. Timeframe: 2 months after the biohackathon'
  hacking_topic: 'Biodiversity

    industry

    Training Platform'
  leads: Marco Anteghini marco.anteghini@wur.nl
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/3
  number: '3'
  number_of_expected_hacking_days: '4'
  project_number: 3
  title: Bioinforming
- abstract: 'BioHackrXiv allows publishing papers for biohackathons and codefests.
    This includes this Elixir biohackathon and the upcoming 48 hour pangenomics hackathon
    in 2022. This year we will expand on the metadata representation, add functionality
    to the PDF preview generator and add IPFS support for publication - that adds
    to the DOI system. We should also look at tying datasets and source code to the
    publications using IPFS or other permanent URIs. These can be integrated using
    a workflow definition (2022 is the year of the workflows!)


    This year it would be an improvement to start reporting on day 1 of the Elixir
    biohackathon for every project in a markdown document that can be used for the
    reporting sessions half-way and at the end of the biohackathon. In fact, if we
    encourage this from the start the publications should be ready for publishing
    at the end of the week.'
  authors: Pjotr Prins, Tazro Ohta and Arun Isaac
  expected_audience: 'Software developers for the Ruby previewer and RDF metadata

    Workflow definition using Conscise CWL

    Social interactions to get publishing going early'
  expected_outcomes: "Improved RDF metadata\nA protocol for early publishing inside\
    \ biohackathons\nURIs for data and source code\nImprove software \nHost a workflow\
    \ publication"
  hacking_topic: 'Compute Platfrom

    Data Platform

    Interoperability Platform

    Tools Platform'
  leads: 'Pjotr Prins

    pjotr.public433@thebird.nl'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/4
  number: '4'
  number_of_expected_hacking_days: '4'
  project_number: 4
  title: BioHackrXiv
- abstract: Bioschemas is a grassroots community effort to improve FAIRness of resources
    in the Life sciences by defining specific Life Science metadata schemas and exposing
    that metadata from resources that have adopted it. Now that some initial types
    have been adopted directly into schema.org, an improved mechanism is required
    to reignite community engagement and encourage profile development. The current
    process for creating or updating Bioschemas profiles and types is technical and
    convoluted which creates accessibility issues that can hamper community participation.
    As adoption of Bioschemas grows and more of the Life Science community considers
    contributing specific types and profiles, a more accessible creation/modification
    process is necessary to avoid a loss in engagement. To drive further Bioschemas
    adoption the community have adopted the Data Discovery Engine (DDE) for profile
    and type development. DDE provides a schema registry and user-friendly tools for
    creating and editing schemas. The goal of this project is to update existing Bioschemas
    community profiles in a targeted and crowd-sourced manner, add new profiles as
    required, and to ensure the documentation is fit for purpose to enable Bioschemas
    contributions at scale.
  authors: Nick Juty, Alasdair Gray and Ginger Tsueng
  expected_audience: "We will target and invite representatives from a number of groups\
    \ to a) update existing profiles, and b) to create new types that are ready to\
    \ go. \nThis will be reps from existing resources and from identified communities\
    \ (some of whim will already be craeting profiles or types)"
  expected_outcomes: '1. Refinement/creation of documentation and tutorials on creating/updating
    Bioschemas Profiles using DDE.

    2. Updating a number of Bioschemas profiles through a group hackathon exercise

    3. Invite targeted participants to work on new profiles

    4. Invite ELIXIR CRDs and DDRs to improve deployment across the e-infrastructure

    - timeframe - mostly during and immediately after the BH'
  hacking_topic: 'Bioschemas

    Data Platform

    Interoperability Platform'
  leads: 'Nick Juty : nsjuty@gmail.com'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/5
  number: '5'
  number_of_expected_hacking_days: '4'
  project_number: 5
  title: Bioschemas - Enabling profile updates through the Data Discovery Engine (DE)
- abstract: The European Reference Genome Atlas (ERGA) has gathered a wide community
    to generate reference genome assemblies for diverse eukaryote species. To this
    end, sequencing platforms have already generated large datasets for several species,
    which now require extensive bioinformatic analyses. Our project aims to build
    an assembly and annotation pipeline, in collaboration with the Vertebrate Genomes
    Project (VGP), to enable newcomers to the field to integrate heterogeneous sequencing
    datasets (PacBio HiFi, Nanopore, Illumina and Hi-C reads) and generate high-quality
    chromosome-level assemblies and gene sets. In addition, we will test new tools
    to identify efficient assembly and annotation strategies. Implementing this pipeline
    within the Galaxy framework will help streamlining the process, while also facilitating
    its access to biologists with limited access to High Performance Computing resources,
    as eukaryote genomes typically require large computational resources. This pipeline
    will also serve as a tutorial to convey technical skills and good practices in
    genome assembly and annotation. Working to establish these pipelines will also
    be vital to this community as they will help serve as standardized and reproducible
    protocols.
  authors: "Nad\xE8ge Guiglielmoni and Giulio Formenti"
  expected_audience: Researchers working on genome assembly and/or annotation
  expected_outcomes: "\u2013 An improved pipeline for assembly of diverse eukaryotic\
    \ genomes\n\u2013 A Galaxy workflow for genome annotation\n\u2013 A committed\
    \ genome assembly community stemming from the interaction between ERGA, Galaxy\
    \ and the VGP\n\u2013 Extended tutorials and guidelines for high-quality genome\
    \ assembly using Galaxy workflows"
  hacking_topic: 'Biodiversity

    Galaxy

    Tools Platform'
  leads: "Nad\xE8ge Guiglielmoni nguiglie@uni-koeln.de"
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/6
  number: '6'
  number_of_expected_hacking_days: '4'
  project_number: 6
  title: Building a robust and reproducible assembly and annotation pipeline for non-model
    eukaryote genomes
- abstract: "Connecting Data: ID conversion plays an essential role in data integration.\
    \ We recently launched the TogoID service (https://togoid.dbcls.jp/), which provides\
    \ ID conversion among a variety of life science databases covering, but not limited\
    \ to, genes, transcripts, variants, orthologs, proteins, structures, compounds,\
    \ glycans, interactions, pathways, diseases, taxonomy, and literature. Key features\
    \ of the TogoID include 1) supporting a wide range of databases, 2) multi-step\
    \ ID conversions, 3) API for automated high-throughput conversions, 4) cloud-based\
    \ hosting for the stable operation, 5) an ontology to semantically represent biological\
    \ meanings of the conversion, and 6) an open-source development model for expanding\
    \ supported databases. The last feature is enabled by the TogoID-config tool (https://github.com/dbcls/togoid-config)\
    \ that defines a workflow to generate ID pairs from original databases, so that\
    \ inclusion of a new database can be easily accomplished.\n\nVisualizing Data:\
    \ Database providers have been suffering from the development cost of visualization\
    \ modules that effectively represents the database contents. MetaStanza provides\
    \ a set of generic visualization modules that take data from any API returning\
    \ the contents in JSON, CSV, TSV, or SPARQL query results format. A list of currently\
    \ available visualizations is available in the MetaStanza showcase at http://togostanza.org/metastanza/,\
    \ and many other visualizations are under development as open-source software.\
    \ MetaStanza has a variety of customization options including parameters and styles.\
    \ As each visualization is implemented as WebComponents, a database user can also\
    \ benefit from reusing the visualization in the user\u2019s page just by copying\
    \ a few lines of the HTML code.\n\nIn this hackathon, we plan to invite ELIXIR\
    \ data providers and seek use cases that meet the requirements of data integration\
    \ and visualization. With TogoID, we expect new ELIXIR database identifiers to\
    \ be connected with external database resources for accelerating integrated use.\
    \ To support this procedure, we will improve the TogoID-config tool to provide\
    \ a generic set of converters for major data formats like CSV, JSON, XML, RDF,\
    \ and flat files that are often used in the life science databases. As for the\
    \ MetaStanza, we will update the implementation of existing visualization components\
    \ to better support ELIXIR data. We also plan to develop additional visualizations,\
    \ especially for biological data such as heatmaps, time series, and geographic\
    \ maps.\n"
  authors: 'Shuya Ikeda (DBCLS)

    Yuki Moriya (DBCLS)

    Tazro Ohta (DBCLS)

    Shuichi Kawashima (DBCLS)

    Mayumi Kamada (Kyoto Univ.)

    Anton Zhuravlev (PENQE Inc.)

    Marleen Dijkman (PENQE Inc.)

    Akio Nagano (PENQE Inc.)'
  expected_audience: 'FAIR data holders

    Data scientists'
  expected_outcomes: 'Integration of several FAIR datasets into the TogoID conversion
    service

    Visualization of FAIR datasets with MetaStanza framework'
  hacking_topic: 'Tools Platform

    Interoperability Platform

    Data Platform'
  leads: Toshiaki katayama (Database Center for Life Science; DBCLS) - ktym@dbcls.jp
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/7
  number: '7'
  number_of_expected_hacking_days: 4 days
  project_number: 7
  title: Connecting and visualizing FAIR data with TogoID and MetaStanza
- abstract: 'Data Management Plans are now considered a key element of Open Science.
    They describe the data management life cycle for the data to be collected, processed
    and/or generated within the lifetime of a particular project or activity. A Software
    Management Plan (SMP) plays the same role but for software. Beyond its management
    perspective, the main advantages of an SMP are providing clear context to the
    software that is being developed, and raising awareness. ELIXIR has developed
    a low-barrier SMP (https://biohackrxiv.org/k8znb/), specifically tailored for
    life science researchers, aligned to the FAIR Research Software principles. The
    ELIXIR SMP has been implemented through the Data Stewardship Wizard, the expert
    system that helps users through smart questionnaires, and is now available as
    a Software Management Wizard (https://smw.ds-wizard.org/).


    Beyond the availability of the service however, equally important is for people
    to learn how to use the ELIXIR SMP. This project aims to build upon the structure
    already designed within the ELIXIR Tools Platform task (https://github.com/elixir-europe/elixir-smp-lesson),
    and produce training material for the use of the ELIXIR SMP, across the five main
    stages of software development: Stage 1, Inception (concept, proposal writing,
    planning and inception); Stage 2, Construction (prototyping, construction and
    implementing core functionality); Stage 3, Application (release and quality assessment);
    Stage 4, Production (production software working on real-world data in a scalable
    and stable manner), and; Stage 5, Publication (Publishing software and/or research
    results obtained with the software). In each stage, priority will be given on
    highlighting which parts of the SMP are the most critical, why these are important
    and what are the main considerations when providing the relevant information.
    Ultimately, having training material for the ELIXIR SMP will facilitate its adoption
    by the wider community.'
  authors: Allegra Via, Fotis Psomopoulos, Eva Martin Del Pico, Leyla Jael Castro
    and Dimitris Bampalikis
  expected_audience: 'Trainers

    Researchers involved in research software development (in any role/capacity)

    Experts in FAIR (for research software, training, etc.)

    Experts from the Train-the-Trainer community'
  expected_outcomes: A first full version of a lesson on the ELIXIR Software Management
    Plan
  hacking_topic: 'Bioschemas

    Tools Platform

    Training Platform'
  leads: Allegra Via allegra.via@gmail.com
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/8
  number: '8'
  number_of_expected_hacking_days: '4'
  project_number: 8
  title: Developing a lesson for the ELIXIR Software Management Plan
- abstract: "Machine learning (ML) models are widely used as tools in life science\
    \ and medical research. However, ML models are scattered across various resources\
    \ including personal websites, git-hub, bitbucket, and supplementary material,\
    \ making it difficult to find, access, and reuse them. We propose to extend BioModels\
    \ (https://www.ebi.ac.uk/biomodels) to support FAIR dissemination of ML models\
    \ in biomedical sciences. BioModels is an ELIXIR deposition database of biomedical\
    \ mechanistic models, hosted at EMBL-EBI and accessed by about 51,000 unique users\
    \ (IPs) annually. BioModels\u2019s infrastructure was recently enhanced to support\
    \ version-controlled dissemination and curation of a wide range of modelling frameworks\
    \ and formats, providing capabilities to host and disseminate ML models. We propose\
    \ to engage with the ML modellers during BioHackathon to support the dissemination\
    \ of their models to BioModels. We will semantically enrich models with controlled\
    \ vocabularies such as Disease and Gene Ontologies adapting the existing metadata-support\
    \ and curation guidelines in BioModels. ML models can be linked with the model\
    \ data hosted within EMBL-EBI and other ELIXIR nodes through cross-references\
    \ using BioModels qualifiers. Using the metadata, the sophisticated search engine\
    \ of BioModels will allow users to easily find and download ML models. We will\
    \ use this BioHackathon to perform a pilot work on FAIR model dissemination via\
    \ BioModels. Firstly, we will engage with ML modellers and identify minimal and\
    \ essential metadata standards for ML models, and adapt the existing interoperable\
    \ COMBINE metadata framework to implement it. We will semantically enrich the\
    \ existing 16 ML models in BioModels (https://www.ebi.ac.uk/biomodels/search?query=submitter_keywords%3AMachine+Learning+Model&domain=biomodels_all).\
    \ Following on, we will solicit ML model submissions from the ELIXIR ML modelling\
    \ community. We will also import and annotate publicly available key ML models\
    \ to extend the collection in BioModels. Through this pilot work, we will demonstrate\
    \ the proof of the concept to disseminate metadata-rich, data and tools cross-referenced\
    \ FAIR ML models via BioModels."
  authors: Rahuman S Malik Sheriff and Henning Hermjakob
  expected_audience: 'Skill sets in participants*: Machine learning modelling (any
    approach), Ontologies, metadata, bioschema, coding (R, Python, etc) (*at least
    any two of these skills)'
  expected_outcomes: "Establish minimal metadata standard (Version 1)  to enhance\
    \ findability of ML model, based on Bioschema and/or BioModels Qualifiers. The\
    \ minimal metadata will cover broader aspects including the biology of the model,\
    \ ML method, data and tools used, features, inputs, and output of the model.\n\
    Identification of key ontologies and extension of COMBINE standard and BioModels\
    \ SOP to annotate ML models \nAnnotation of existing ML models established metadata\
    \ standards in BioModels. \nExternal submission of ML models from the ELIXIR community\
    \ to BioModels \nPublicly available pilot collection of FAIR ML models in BioModels"
  hacking_topic: 'Bioschemas

    Data Platform

    Machine learning

    Tools Platform'
  leads: Rahuman S Malik Sheriff (sheriff@ebi.ac.uk)
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/9
  number: '9'
  number_of_expected_hacking_days: '4'
  project_number: 9
  title: Disseminating FAIR Machine Learning Models via BioModels
- abstract: "RO-Crate (https://doi.org/10.3233/DS-210053) is a generic packaging format\
    \ containing datasets and their description using standards for FAIR Linked Data.\
    \ Based on rich schema.org metadata, such datasets can be interpreted as workflow\
    \ definitions, datasets, data associated with workflow invocations, inputs, outputs,\
    \ etc.\n\nThe Galaxy workflow framework is handling all of those objects and supports\
    \ users in the daily RDM. Integrating RO-Crate deeply into Galaxy and offering\
    \ import and export options of various Galaxy objects as Research Objects will\
    \ greatly standardize and improve the RDM in Galaxy and smoothen the UX as well\
    \ as improving interoperability with other systems.\n\nThe low hanging fruit of\
    \ this proposal is to add support for import/export of RO-Crates following its\
    \ Workflow profiles. Those Crates should contain as much metadata as the Galaxy\
    \ framework can provide. This includes workflow metadata such as Licence, Creator,\
    \ CWL-abstract description, workflow history, contextually also references (DOIs,\
    \ bio.tool IDs), EDAM terms, and formats of inputs/outputs of data processing\
    \ of each step of the workflow.\n\nExports of History and Workflow Invocations\
    \ need work on the corresponding RO-Crate profile and on the Galaxy codebase.\
    \ RO-Crates already can be visualized, this would add a human-readable HTML rendering\
    \ of the Galaxy export and metadata. Close collaboration between RO-Crate and\
    \ Galaxy developers will speed up this development; the groundwork could be completed\
    \ during the Biohackathon so that both Crates will be supported by the Galaxy\
    \ 23.01 release.\n\nData Stewardship Wizard (DSW) is a tool for data management\
    \ planning with focus on FAIR metrics, proper guidance and integration with other\
    \ tools in the data stewardship domain. Thus, similarly to utilising RO-Crates\
    \ in Galaxy, the import and export functionality would be highly beneficial for\
    \ DSW in terms of promoting interoperability and FAIRness in general. Existing\
    \ RO-Crates can be used to pre-fill specific parts of DMPs, and vice versa, RO-Crates\
    \ can be created or initiated from a DMP. Such support of RO-Crates in DSW can\
    \ lay a foundation for closer integration with Galaxy and potentially other ELIXIR\
    \ Tools platform components. \n\nThis project can benefit from collaborations\
    \ with other Biohackathon projects discussed during the 2022 Tools Platform meeting\
    \ such as \u201CScientific and technical enhancement of bioinformatics software\
    \ metadata using the Tools Ecosystem open infrastructure\u201D as it will also\
    \ be leveraging workflow and software metadata from the same resources.\n"
  authors: "Ignacio Eguinoa, Stian Soiland-Reyes, Paul De Geest, Bj\xF6rn Gr\xFCning\
    \ and David L\xF3pez Tabernero, Marek Such\xE1nek, Paulette Lieby and Jan Slifka"
  expected_audience: '- Data/Workflow Platform developers (e.g. Galaxy)

    - Tool maintainers/packagers

    - Metadata/ontology experts (e.g. Bioschemas, JSON-LD)

    - Python developers

    - Ruby developers

    - Researchers producing galaxy histories/workflows


    This topic involves partners from at least:

    - ELIXIR-UK

    - ELIXIR-BE

    - ELIXIR-ES

    - ELIXIR-DE


    We will extend the virtual invitation to:

    - Galaxy Europe developers

    - RO-Crate community https://www.researchobject.org/ro-crate/community.html

    - Workflow Run RO-Crate task force https://www.researchobject.org/workflow-run-crate/

    - BioCompute object community https://biocomputeobject.org/

    - Workflows Community Initiative (FAIR Computational Workflow working group) https://workflows.community/groups/fair/

    Participants from related projects (incl. EOSC-Life, SYNTHESYS+, BY-COVID, RELIANCE)
    developing workflow provenance methods

    '
  expected_outcomes: 'From the hackathon:

    - Galaxy export of history, adding workflow invocation metadata following interoperable
    FAIR standards

    - Improvements to specifications of RO-Crate and the Workflow/WorkflowRun provenance
    profiles

    - Prototype of Galaxy import of RO-Crate into history

    - Improvements to RO-Crate libraries (Python, Javascript, Ruby) - new languages
    welcome!

    - Prototype embedding of resolved bio.tools/EDAM metadata as part of Galaxy export

    - Mapping between RO-Crates and DSW Knowledge Model

    - Import and export of RO-Crates functionality in DSW projects

    - Analysis of direct DSW-Galaxy integration and implementation plan


    Following the hackathon :

    - Tighter collaboration between Galaxy, DSW, and RO-Crate developers

    - Galaxy release (23.01) with RO-Crate support

    - DSW-Galaxy integration based on analysis and plan

    - Release new DSW features and updated content

    - Documentation of FAIR data management with Galaxy, DSW, and RO-Crate, e.g. for
    RDMKit

    - Further integration between UseGalaxy.eu, ELIXIR Tools platform components (bio.tools,
    WorkflowHub, EDAM) and EOSC-Life Tools Collaboratory (Life Monitor, WfExS)

    - Report on new features, insights, and other outcomes of the hackathon published
    via BioHackrXiv

    '
  hacking_topic: "\"RO-Crate,\nResearch Object,\nMetadata,\nWorkflow invocation,\n\
    Galaxy,\nData packaging,\nBioschemas,\nProvenance, \ndata management plan,\ntool\
    \ integration,\nsoftware development kit,\ndata import\""
  leads: "Ignacio Eguinoa (ignacio.eguinoa@psb.ugent.be)\nMarek Such\xE1nek (marek.suchanek@fit.cvut.cz),\
    \ co-lead\n"
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/10
  number: '10'
  number_of_expected_hacking_days: "4 Days \u2013 due to virtual participation, hacking\
    \ can extend into pre/post Biohackathon hacking days as we did in 2021."
  project_number: 10
  title: Enhance RDM in Galaxy and DSW by utilising RO-Crates
- abstract: Knowledge Graphs (KGs) such as Wikidata act as a hub of information from
    multiple domains and disciplines, and is crowdsourced by multiple stakeholders.
    The vast amount of available information makes it difficult for researchers to
    manage the entire KG, which is also continually being edited and changing its
    content. It is necessary to develop tools that extract snapshots and subsets for
    some specific domains of interest. These subsets help researchers by reducing
    costs and ease accessbility to data of interest. In the last two biohackathons,
    we have identified this issue and created prototypes to extract subsets easily
    applicable to Wikidata, as well as to define a map of the different approaches
    used to tackle this problem. Building on those outcomes, we aim to enhance subsetting
    in both definitions using Entity schemas based on Shape Expressions and extraction
    algorithms, with a special focus on the biomedical domain captured by entity schemas
    like the one defined in the GeneWiki project. Our first aim is to develop complex
    subsetting patterns to cover subsetting based on qualifiers and references for
    enhancing credibility of datasets. Our second aim is to establish a faster subsetting
    extraction platform applying new algorithms based on Apache Spark and new tools
    like a document-oriented DBMS platform. During this biohackathon, we aim to explore
    reuse workflows of Wikidata subsets specifically with respect to drug repurposing.
    The biohackathon will assist in an evaluation of existing nodes and edges on drug-target
    interactions categories within Wikidata, and if these are in need of updates as
    well as deeper annotation. We would also aim to deliver machine readable schemas
    of drug-target interactions in Wikidata for future data reuse.
  authors: 'Jose Emilio Labra Gayo

    Seyed Amir Hosseini Beghaeiraveri

    Sabah Ul-Hasan

    Andra Waagmeester

    Tiago Lubiana

    Rianne Fijten'
  expected_audience: 'Biomedical domain experts

    Data modelers with interest in Wikidata and knowledge graphs

    Developers with Python/Java/Javascript/Scala skills

    Data engineers with Knowledge on Spark and parallelization algorithms'
  expected_outcomes: "1- Subsetting based on complex patterns, i.e., having complicated\
    \ definitions to delicately define the boundaries of the subset.\n2- Subsetting\
    \ based on contextual metadata, e.g., considering references/qualifiers in Wikidata\n\
    3- Creation of biomedical subsets of Wikidata based on complex schemas like the\
    \ ones defined in the GeneWiki project \n4- Deployment, Enrichment and transformation\
    \ techniques and tools for the subsets created\n5 - Improved biomedical schemas\
    \ in Wikidata \n6 - Enhanced annotation of biomedical nodes and edges"
  hacking_topic: Bioschemas, Cancer, Covid-19, Data Platform, Federated Human Data,
    Machine learning, Plant Sciences, Rare Disease, Tools Platform
  leads: 'Jose Emilio Labra Gayo, labra@uniovi.es

    Seyed Amir Hosseini Beghaeiraveri, sh200@hw.ac.uk

    Sabah Ul-Hasan - bysabahulhasan@gmail.com

    Andra Waagmeester'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/11
  number: '11'
  number_of_expected_hacking_days: '4'
  project_number: 11
  title: Enhancement and Reusage of Biomedical Knowledge Graph Subsets
- abstract: "MGnify is EMBL-EBI\u2019s metagenomics resource, which is part of ELIXIR\
    \ Metagenomics Community. The resource has had a notable track record of ensuring\
    \ We recently launched a Notebook Server to provide an online, Jupyter Lab environment\
    \ for users to explore programmatic access to MGnify\u2019s datasets using Python\
    \ or with R. This ready to use environment and example analysis notebooks bridge\
    \ the gap between the ease but limitations of browsing the MGnify website, and\
    \ the complexity but possibilities of installing a local environment to work with\
    \ data stored in MGnify. Particular goals of the Notebook Server include reproducible\
    \ downstream analyses, user empowerment through best-practice examples and fast\
    \ workflows from datasets to publication-ready graphics, and code-as-documentation\
    \ training materials for users of MGnify.\n\nWe have three objectives for the\
    \ BioHackathon:\n\nFirst, to increase the breadth of example notebooks to cover\
    \ the entire of the MGnify API surface. This means users will be able to jump\
    \ from any resource on the MGnify website into a Jupyter Notebook ready to read\
    \ and analyse that dataset.\n\nSecond, to showcase examples using SIAMCAT\u2019\
    s statistical and machine-learning frameworks for comparative metagenomics (https://siamcat.embl.de/).\
    \ This builds upon the existing integration of MGnifyR (https://github.com/beadyallen/MGnifyR),\
    \ and towards our vision of curating a repository of exemplary packages and workflows\
    \ from collaborators and the community.\n\nThird, to explore integration with\
    \ the Galaxy Europe project. Galaxy supports a broad range of tools, including\
    \ Jupyter Notebooks. Serving the MGnify Notebook experience from Galaxy Europe\
    \ infrastructure can unlock a wider set of possibilities for users, as well as\
    \ provide a persistent analysis workbench."
  authors: Martin Beracochea and Alexander Rogers
  expected_audience: '5'
  expected_outcomes: 'BioHackathon outcomes:

    - Expand the MGnify Notebook Server to include example Jupyter Notebooks, in both
    Python and R, to read in and tabulate or visualise: Samples, Runs, Analyses, Publications,
    and MAGs

    - Integrate the SIAMCAT package, and create an example of association testing
    from MGnify API data

    - Create a proof-of-concept for serving MGnify Notebooks via the Galaxy Europe
    platform


    Long-term expected outcomes:

    - Integration of MGnify Notebooks in the Galaxy Europe platform . (6 months)

    - Establish a catalogue of notebooks to allow scientist to share their approaches,
    which can be either used to ensure reproducibility or allow the methods to be
    applied to different datasets. (8 months)'
  hacking_topic: 'Biodiversity

    Data Platform

    Interoperability Platform

    Marine Metagenomics'
  leads: Martin Beracochea - mbc@ebi.ac.uk
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/12
  number: '12'
  number_of_expected_hacking_days: '4'
  project_number: 12
  title: Empowering the community with notebooks for bespoke microbiome analyses
- abstract: 'Nearly two years after the first report of SARS-CoV-2 in Wuhan, China,
    the COVID-19 pandemic has affected more than 485 million people. Wastewater surveillance
    has attracted extensive public attention during the SARS-CoV-2 pandemic, as a
    passive monitoring system to complement clinical and genomic surveillance activities.
    Several methods and protocols are already in place that effectively facilitate
    the detection and quantification of viral RNA in wastewater samples, and concentrations
    in wastewater have been shown to correlate with trends in reported cases.


    With exploratory projects having shown promise, it is now important to coordinate
    among initiatives for establishing community standards and effectively building
    an inventory of the available software tools and services, in order to ultimately
    simplify the deployment of end-to-end genomic wastewater surveillance pipelines
    and increase the adoption of such promising monitoring methods across the wider
    community. The first step in this direction would be to identify and catalogue
    the relevant methodologies and bioinformatics workflows that are integral components
    of the lifecycle of genomic data derived from wastewater samples, combining into
    a coherent structure.


    The main goal of this project will be to review, collate and offer a first attempt
    towards integrating, standardising and reporting different approaches that are
    available for genomic wastewater surveillance. Leveraging the collective expertise
    of the ELIXIR COVID19 Wastewater Surveillance Working Group, the project will
    focus on creating a comprehensive landscape of components (e.g. modules, tools
    etc) that can be effectively utilised for end-to-end genomic wastewater surveillance
    pipelines. Building on this landscape, this project will attempt a first integration
    of selected modules within the ELIXIR Tools Platform ecosystem (Galaxy, bio.tools,
    WorkflowHub etc). Ultimately, this process will be piloted by an effort to integrate
    and expand new tools into this framework, defining the roadmap towards a standardised  genomic
    wastewater surveillance ecosystem.


    '
  authors: "Fotis Psomopoulos, B\xE9r\xE9nice Batut, Ioannis (Jiannis) Ragoussis,\
    \ Anna Krivjanska, Katharina Lauer, Ivan Topolsky, David Dreifuss, Kim Jablonski"
  expected_audience: 'Researchers active in national wastewater surveillance efforts,
    experts in genomic data production and management - including metadata standards,
    bioinformaticians including people who are running wastewater surveillance pipelines

    workflow expertise (python, snakemake, nextflow), WES expertise, R/Python/HTML/CSS/Javascript
    developers

    pilot website, UI experience, Data Visualization

    '
  expected_outcomes: "Landscape of components (e.g. modules, tools etc) that can be\
    \ effectively utilised for end-to-end genomic wastewater surveillance pipelines.\
    \ Examples might include:\nmodules by the V-pipe teams\ntools efforted/supported\
    \ by other teams joining this project\nImplement a collection of genomic wastewater\
    \ surveillance using the ELIXIR Tools Ecosystem\nCreate bio.tools \u201Cwastewater\
    \ surveillance\u201D domain\nPublishing pipelines on WorkflowHub\nEstablish a\
    \ community-based genomic wastewater surveillance methodologies resource, where\
    \ protocols can be posted and made publicly available.\nPilot the process of adding\
    \ additional components by integrating them into pipeline(s). This will entail\
    \ activities such as:\nStandardising the formats for interoperability of the involved\
    \ tools, incl. definitions of variants\nA prototype integrated framework around\
    \ Galaxy\nComplementing existing pipelines like V-pipe\n\ncheck here for correct\
    \ bullet point formatting"
  hacking_topic: 'Training Platform, Tools Platform

    Galaxy Community

    COVID-19; Influenza; Emerging Pathogen Monitoring

    GA4GH'
  leads: 'Ivan Topolsky - ivan.topolsky@sib.swiss

    Fotis Psomopoulos - fpsom@certh.gr

    '
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/13
  number: '13'
  number_of_expected_hacking_days: '4'
  project_number: 13
  title: 'Exploring the landscape of the genomic wastewater surveillance ecosystem:
    a roadmap towards standardisation'
- abstract: "A major challenge in the use of ontologies is that the formal terminology\
    \ used in the ontology hierarchy does not always match the \"layman\u201D language\
    \ commonly used by practitioners. This causes two problems: (1) in biocuration,\
    \ text strings are often significantly different from their corresponding ontology\
    \ terms; and (2) ontology terms do not always match the common terminology.\n\n\
    Tools to address (1) include ZOOMA and OntoString developed at EMBL-EBI for the\
    \ Human Cell Atlas Data Coordination Platform and EOSCLife. However, (2) is less\
    \ well explored. Some ontologies are beginning to provide \u201Clayperson\u201D\
    \ synonyms for terms. However, this approach is not standardised, and lacks support\
    \ in ontology tooling such as the Ontology Lookup Service (OLS). We will therefore\
    \ explore how this functionality can be implemented, so that users can choose\
    \ between formal and informal language when browsing an ontology.\n\nSecondly,\
    \ we will explore how this approach can be used by the microbial biotechnology\
    \ ELIXIR community to make their applications more user friendly and FAIR compliant.\
    \ FAIR data standards and ontologies are critical for the FAIR compliance and\
    \ usability of biological design knowledge. Semantically well-defined data models\
    \ are available; e.g. SBOL and SyBiOnt. However, these efforts have not primarily\
    \ taken the needs of the tool user into account. Their vocabulary is therefore\
    \ in many cases significantly different from terms used by experimentalists, impeding\
    \ biocuration and adoption of FAIR principles.\n\nWe will therefore construct\
    \ a presentation layer vocabulary for non-developer users of FAIR synthetic biology\
    \ tools and repositories, with BioHackathon participants and the wider community.\
    \ We will incorporate this vocabulary into existing FAIR workflows to make them\
    \ more accessible to end-users while retaining their underlying ontological representation."
  authors: James McLaughlin (primary contact), Anil Wipat
  expected_audience: 'Java developers to contribute to OLS code.

    Researchers in the synthetic biology and biotechnology domain. Especially ontology
    builders, tool builders. We will also need experimental scientists - these will
    be invited if the project is successful. We would also like to work closely with
    the RDMKit project as joint work already carried out at the previous BioHackathon
    is very relevant.'
  expected_outcomes: 'The first draft of an application ontology for synthetic biology/biotechnology
    - completion by first month after the Biohackathon

    Support for alternate terminologies implemented in OLS code - By the end of the
    biohackathon

    A microbial biotechnology white paper - submitted as an ELIXIR F1000 within 3
    months of the event

    A project homepage and contributors network - Established at the Biohackathon

    An SBOL SEP standard update proposal - 6 months after the event'
  hacking_topic: Compute Platform, Data Platform, Interoperability Platform, Microbial
    Biotechnology, Tools Platform
  leads: jmcl@ebi.ac.uk, anil.wipat@ncl.ac.uk
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/14
  number: '14'
  number_of_expected_hacking_days: '4'
  project_number: 14
  title: FAIR knowledge representation for user facing applications
- abstract: "Machine Learning (ML) methods are becoming ever more prevalent across\
    \ all domains in Life Sciences. However, a key component of effective ML is the\
    \ availability of large datasets that are diverse and representative. In the context\
    \ of health systems, with significant heterogeneity of clinical phenotypes and\
    \ diversity of healthcare systems, there exists a necessity to develop and refine\
    \ unbiased and fair ML models. Synthetic data are increasingly being used to protect\
    \ the patient\u2019s right to privacy and overcome the paucity of annotated open-access\
    \ medical data. Synthetic data and generative models can address these challenges\
    \ while advancing the use of ML in healthcare and research.\n\nFollowing up the\
    \ efforts currently undertaken in the ELIXIR Health Data and the Machine Learning\
    \ Focus Groups around the synthetic health data landscape, this project will focus\
    \ on the health data providers' need for a ready-to-use synthetic data platform\
    \ which is assessed by health data experts, researchers, and ML specialists. Aligned\
    \ to ELIXIR Health Data Focus Group\u2019s objectives, we aim at building an infrastructure\
    \ for synthetic health data offering a dockerized synthetic data generator based\
    \ on the open-source libraries Synthetic Data Vault (SDV) (github.com/sdv-dev)\
    \ and ydata-synthetic (github.com/ydataai) with state of the art ML methods. This\
    \ will enable users to generate synthetic data that has the same structure and\
    \ statistical properties as the original dataset from a variety of data types\
    \ (clinical, variational or omics). Despite the capacity to generate their own\
    \ datasets, a set of exemplary datasets will be publicly available in appropriate\
    \ repositories and will include rich metadata descriptions according to the DOME\
    \ recommendations (https://dome-ml.org/) and GA4GH (ga4gh.org) standards. OpenEBench\
    \ (openebench.bsc.es) will host a community of practice for comparing different\
    \ approaches for synthetic data generation."
  authors: "N\xFAria Queralt Rosinach, Soumyabrata Ghosh, Venkata Satagopam, Tim Beck,\
    \ Davide Cirillo, Wei Gu, Fotis Psomopoulos, Dylan Spalding and Salvador Capella-Gutierrez"
  expected_audience: "Python developer(s) with experience in data science libraries\
    \ + UI \nResearchers developing workflows\nSynthetic data experts and users\n\
    Experts on statistics + ML\nResearcher(s) with experience in EHR and clinical\
    \ data\nResearcher(s) with experience in various omics data-types\n\nWe would\
    \ like to invite two specific people from Europe who are critical to the success\
    \ of the project (name /institute/email):\n\nProf. Mihaela van der Schaar \nUniversity\
    \ of Cambridge \nmv472@damtp.cam.ac.uk\n(https://www.vanderschaar-lab.com/)\n\n\
    Prof. Patrick Ruch\nHEG / HESSO Geneva and Group Leader at SIB (Text Mining group)\n\
    patrick.ruch@hesge.ch\nhttps://orcid.org/0000-0002-3374-2962\n(http://bitem.hesge.ch/people/patrick-ruch)\n\
    CINECA Synthetic Datasets"
  expected_outcomes: 'Hackathon outcomes:

    1. Design and development of a synthetic data generation workflow in Python using
    SDV, and ydata-synthetic libraries (4 days)

    2. Development of a web interface (with Python Stremlit package or similar) to
    run the workflow with configuration settings (4 days)

    3. Packaging in a docker which can shipped to data provider location (1 day)


    As long-term outcomes, we are planning to submit a manuscript on the synthetic
    health data infrastructure developed following ELIXIR requirements. The development
    of the infrastructure per se is a long-term outcome, where we envision adding
    other components such as implementing evaluation metrics to assess the quality
    of the generated synthetic data and a direct deposition of the synthetic datasets
    to recommended repositories.'
  hacking_topic: 'Data Platform

    Federated Human Data

    GA4GH partnership

    Machine learning

    Tools Platform'
  leads: "N\xFAria Queralt Rosinach, n.queralt_rosinach@lumc.nl"
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/15
  number: '17'
  number_of_expected_hacking_days: 4 days
  project_number: 15
  title: Infrastructure for Synthetic Health Data
- abstract: "EasyBuild is a community effort to develop a software build and installation\
    \ framework that allows you to manage (scientific) software on High Performance\
    \ Computing (HPC) systems in an efficient way. As its name suggests, EasyBuild\
    \ makes software installation easy by automating builds, making previous builds\
    \ reproducible, resolving dependencies, and retaining logs for traceability. It\
    \ is also one of the components of the European Environment for Scientific Software\
    \ Installations (EESSI), a collaboration between different European HPC sites\
    \ and industry partners, with the common goal to set up a shared repository of\
    \ scientific software installations that can be used on a variety of operating\
    \ systems and computer architectures. It can be applied in a full size HPC cluster,\
    \ a cloud environment, a container or a personal workstation.\n\nWith the deluge\
    \ of data in the genomics field (e.g., clinical data) and the concomitant development\
    \ of new technologies, the number of data analysis software has exploded in recent\
    \ years. The fields of bioinformatics and cheminformatics follow this same trend\
    \ with ever more developments to optimize and parallelize analyses. The bioinformatics\
    \ field is now the main provider of new software in EasyBuild. Developers of those\
    \ tools are not always professional developers, and they do therefore not always\
    \ follow best practices when releasing their software. As a result, many tools\
    \ are complicated to install, making them ideal candidates for porting their installation\
    \ to EasyBuild so that they become more easily accessible to end users.\n\nWe\
    \ propose to introduce users to EasyBuild and EESSI, and to port new software\
    \ to EasyBuild/EESSI (e.g., the participant\u2019s own or favourite software),\
    \ thereby making it available and discoverable to the entire EasyBuild community.\
    \ In parallel we would like to build bridges between EESSI and Galaxy to make\
    \ the scientific software more accessible to researchers in the domain."
  authors: "S\xE9bastien Moretti, Kenneth Hoste, Alan O'Cais, Jurij Pe\u010Dar and\
    \ Elisabeth Ortega"
  expected_audience: '- Software users.

    - Software developers.

    - Galaxy developers and users.

    - The EasyBuild and the EESSI communities.'
  expected_outcomes: "- Extend domain software supported by EasyBuild (days to weeks).\n\
    - Introduce EasyBuild/EESSI to software developers and users (days to weeks).\n\
    - Create communication paths and technical bridges between EasyBuild/EESSI and\
    \ Galaxy (mix both communities) (4-6 months).\n- Evaluating performance of popular\
    \ bioinformatics software that\u2019s available through Galaxy, compare with installations\
    \ provided via EasyBuild and EESSI (4-6 months).\n- Software developers can maintain\
    \ their own software in EasyBuild (weeks to years)."
  hacking_topic: 'Compute Platfrom

    EOSC-life

    Galaxy

    Tools Platform'
  leads: "S\xE9bastien Moretti (sebastien.moretti@sib.swiss)\nKenneth Hoste (kenneth.hoste@ugent.be)\n\
    Alan O\u2019Cais (alan.ocais@cecam.org)\nJurij Pe\u010Dar (jurij.pecar@embl.de)\n\
    Elisabeth Ortega (elisabeth.ortega@hpcnow.com)"
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/16
  number: '15'
  number_of_expected_hacking_days: '4'
  project_number: 16
  title: Make your own or favourite software available on your cluster with EasyBuild/EESSI
- abstract: For some years now, the scientific community has come to recognize the
    need of sharing not only final methods and results via scholarly publications
    but also complementary research objects (ROs) such as software and data. To maximize
    their usefulness, ROs should be accompanied by metadata, interconnected to each
    other in meaningful ways, and made as open as possible (and as close as necessary).
    Linked Open Science (i.e., Open Science plus Linked Open Data extended to all
    sorts of ROs) deals with the effective combination across these three dimensions
    to improve, for instance, transparency and reproducibility in science. FAIR and
    openness efforts around data have already improved the situation but more needs
    to be done for other ROs such as software, workflows, machine learning, grants,
    management plans, etc. At this BioHackathon, we aim at defining metadata schemas
    under the Bioschemas umbrella, for not yet covered ROS. In particular, we plan
    to work on metadata for management plans and machine learning but we are open
    to any other ROs that participants are interested in. We will base our metadata
    schemas on previous work done by two focus groups part of the ELIXIR Tools Platform,
    viz. the Good Practices group which provides a questionnaire for Software Management
    Plans, and the Machine Learning group which provides the DOME recommendations
    for supervised learning. We will also include work done by groups in the Research
    Data Alliance viz. the Data Management Plans Common Standards Working Group and
    the FAIR for Machine Learning Interest Group, as well as analyses on machine learning
    metadata carried out by the German national project NFDI4DataScience.
  authors: Leyla Jael Castro, Ivan Micetic and Dietrich Rebholz-Schuhmann
  expected_audience: '- People with some knowledge on metadata schemas

    - People with some knowledge on Data/Software Management Plans

    - People with some knowledge on parameters and good practices for Machine Learning

    - People interested in research metadata'
  expected_outcomes: '- Metadata assessment on some platforms supporting the selected
    research objects (e.g., related to machine learning or research management plans)

    - Metadata crosswalk for selected research objects

    - Draft definition of Bioschemas profiles for selected research objects'
  hacking_topic: 'Bioschemas

    Interoperability Platform

    Machine learning

    Tools Platform'
  leads: '- Leyla Jael Castro (ljgarcia@zbmed.de)

    - Dietrich Rebholz-Schuhmann (rebholz@zbmed.de)

    - Ivan Micetic (ivan.micetic@unipd.it)'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/17
  number: '16'
  number_of_expected_hacking_days: '4'
  project_number: 17
  title: Metadata schemas supporting Linked Open Science (with a focus on reproducibility)
- abstract: 'mOWL is a software library that incorporates several methods to generate
    embeddings of entities in ontologies. This project started during the BioHackathon
    Europe edition in 2021, where we made significant progress in setting the bases
    of the library, developing some methods, creating datasets, and starting the documentation.
    For this year, we propose the continuation of the development of mOWL. The current
    state of mOWL contains several methods categorized into graph-based, syntactic,
    and semantic. Furthermore, we provide some datasets related to protein-protein
    interactions as well as Jupyter notebook tutorials. This project can be continued
    and extended by adding more methods, optimizing the existing ones and creating
    other functionalities such as a standardized evaluation framework.

    Additionally, documentation for the library can also be improved. We expect to
    have a fully working version that we can publish in the main Python package repositories
    such as PyPi and Conda.

    The project is available at https://github.com/bio-ontology-research-group/mowl.
    A testing version of the library is available at https://test.pypi.org/project/mowl-borg/
    and current documentation is available at https://mowl.readthedocs.io/en/latest/index.html'
  authors: Fernando Zhapa-Camacho, Maxat Kulmanov and Robert Hoehndorf
  expected_audience: "Participants can provide use cases, implement algorithms, design\
    \ new algorithms, test the library, and provide documentation and tutorials. Skills\
    \ needed:\n\u2022 machine learning\n\u2022 Python, Java or Scala programming\n\
    \u2022 ontologies, Web Ontology Language (OWL)\n\u2022 reasoning\n\u2022 knowledge\
    \ graphs"
  expected_outcomes: 'A library and toolkit, together with a set of biomedical use
    cases/examples and

    documentation. It is expected to be done in 4 days.'
  hacking_topic: 'Interoperability Platform

    Machine learning

    Tools Platform'
  leads: Maxat Kulmanov, maxat.kulmanov@kaust.edu.sa
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/18
  number: '18'
  number_of_expected_hacking_days: 4 days
  project_number: 18
  title: 'MOWL: A library for Machine Learning with Ontologies'
- abstract: "Nightingale is an open source library of visual components for sequence\
    \ information. Most of the components are centred around the idea of a protein\
    \ feature viewer. They have been adopted by recognised projects such as UniProt,\
    \ InterPro, PDB, and OpenTargets. \nThe library includes other biological related\
    \ components such as the structure viewer that wraps the molstar viewer, the textarea\
    \ used in HmmerWeb for DNA sequence search, and the heatmap used in InterPro to\
    \ display confidence levels of RoseTTAFold models.\nDuring biohackathon 2021 we\
    \ made considerable progress on refactoring the core of the library, rewriting\
    \ it in typescript and using LitElements as a framework. This work has continued\
    \ since then, and a release-candidate of the core will be ready by this year\u2019\
    s biohackathon. \nOpenEBench (https://openebench.bsc.es) is the ELIXIR gateway\
    \ to benchmarking evaluations and technical monitoring for bioinformatics tools,\
    \ web servers, and workflows. It offers reusable UI components (widgets) for data\
    \ visualization and representation, to be placed in other web infrastructures,\
    \ distributed as simple HTML snippets/npm packages along with a JavaScript file.\n\
    An objective of this year's biohackathon is to migrate all Nightingalethe core\
    \ components into using the new core, taking advantage of its typed system and\
    \ new architecture, which should simplify the components' code and make it more\
    \ stable and extensible. Furthermore this objective includes updating our showcase\
    \ website using the storybook library, for which a first prototype was created\
    \ in external collaboration during last year\u2019s hackathon.\nAnother objective\
    \ is to create a prototypic implementation of the OpenEBench widget library incorporating\
    \ the state-of-the-art technology core Nightingale is using, sharing their past\
    \ learnings, and resolving a range of down-sides, enabling re-usability outside\
    \ of the OpenEBench ecosystem.\nFinally we aim to set up guidelines and processes\
    \ of how to develop, and review, new re-usable web widgets/components in the community.\n"
  authors: "Gustavo A. Salazar\nAur\xE9lien Luciani\nDaniel Rice\nXavier Watkins\n\
    Dominik Br\xFCchner\nSalvador Capella Gutierrez"
  expected_audience: "Ideally web developers with experience in typescript and web\
    \ components to contribute to the re-factoring. \nOther developers are welcome\
    \ to contribute by using and/or testing nightingale components.\nUsers of biological\
    \ visualisations who want to share their feedback. \nData visualization users\
    \ (defining requirements)\nSoftware architects\n"
  expected_outcomes: "Re-factor the core nightingale components:\nTrack\nInterPro\
    \ Track\nSequence\nColoured Sequence\nVariation\nStructure\nNavigation\nManager\n\
    Interaction viewer\nFilter\nVariation Graph\nLine Graph\nData table\nTooltip\n\
    Alignments\nHeatmap\nNightingaleSunburst\nTextarea Sequence\nPlayground Area\n\
    \nIncrease the test coverage of the new Nightingale core.\nMake Nightingale core\
    \ reusable outside of the scope of its core components. This will allow third\
    \ parties to take advantage of the core functionality, and will make the process\
    \ of including external components into the library simpler. \nWe expect the following\
    \ outcomes in the shared core functionality collaborating with the OpenEBench\
    \ visualization library project:\nShared technology foundation between Nightingale\
    \ and OpenEBench Widgets (separating the Nightingale core)\nPrototypic implementation\
    \ of at least one widget (Reusable; API independent; Directly usable as WebComponents)\n\
    Prototypic implementation of widget library storybook, showcasing usage and re-usage\n\
    Setting up a work-flow, and guidelines for further collaboration and developing\
    \ new components\n\nCommon Output:\nGuidelines and processes of how to develop,\
    \ and review, new re-usable web widgets/components in the community.\n"
  hacking_topic: 'Tools platform

    Data Platform

    Proteomics

    Human Copy Number Variation

    Intrinsically Disordered Community

    Machine learning

    '
  leads: 'dominik.bruchner@bsc.es

    gsalazar@ebi.ac.uk'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/19
  number: '19'
  number_of_expected_hacking_days: '4'
  project_number: 19
  title: Nightingale 4.0 - Reusable web components for accelerating end-users access
    to tools platform metadata
- abstract: 'The European Genome-phenome Archive (EGA) is a service for permanent
    archiving and sharing personally identifiable genetic and phenotypic data resulting
    from biomedical research projects. The Federated EGA, consisting of the Central
    and Federated EGA nodes, will be a distributed network of repositories for sharing
    human -omics data and phenotypes. Each node of the federation is responsible for
    its own infrastructure and the connection to the Central EGA. Currently, the adoption
    and deployment of a new federated node is challenging due to the complexity of
    the project and the diversity of technological solutions used, in order to ensure
    the secure archiving of the data and the transfer of the information between the
    nodes.


    The goal of this project is to develop a suite consisting of simple scripts that
    would help newcomers to the federation to deeply understand the main concepts,
    while enabling them to get involved in the development of the technology as quickly
    as possible.


    In order to achieve that, we are planning to focus on the main pipeline, handling
    the archiving of the data submitted by users. Specifically, the goal is to create
    a number of scripts that would lead the user/developer through the process followed
    from submitting a file to archiving it and making it available for downloading.
    The scripts will shed light on the processes under the hood, including the messaging
    between the services, the records stored in the database as well as the tools
    used for encrypting and decrypting the data. By the end of the biohackathon, we
    aim to have a suite that will ease the onboarding of new members of the Federation.'
  authors: Stefan Negru, Johan Viklund and Dimitrios Bampalikis
  expected_audience: 'Backend developers with a little familiarity with go

    Experience with docker, containers, RabbitMQ, PostgrerSQL, S3'
  expected_outcomes: "During the hackathon:\n * Recognize the aspects that make the\
    \ adoption of the existing infrastructure difficult based on nodes that are interested\
    \ to join\n * Develop script(s) for encryption and submission of data\n * Develop\
    \ easy to use scripts for base pipeline for showing:\n   * Messaging between services\n\
    \   * Records stored in the database\n\nLongterm:\n * Easy to setup local environment\
    \ with synthetic data to evaluate the nordic federated ega pipeline. ~6 months\n\
    \ * Templating a system to setup the nordic federated ega pipeline using different\
    \ infrastructure providers, such as with openstack, kubernetes, amazon. ~12 months\
    \ after hackathon"
  hacking_topic: 'Compute Platfrom

    Data Platform

    Federated Human Data

    Training Platform'
  leads: stefan.negru@csc.fi
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/20
  number: '20'
  number_of_expected_hacking_days: '4'
  project_number: 20
  title: Onboarding suite for Federated EGA nodes
- abstract: "The countries Finland, Sweden, Norway, Denmark and Estonia are collaborating\
    \ in the NeIC Heilsa project to develop software and operate federated EGA nodes.\
    \ We want to bring developers from all partnering countries together to work on\
    \ an operator dashboard for our software stack.\n\n\nAs we move into a mature\
    \ operational ecosystem there is a need for both System Administrators and Helpdesk\
    \ staff to be able to control and inspect the system. We need to answer questions\
    \ related to operations, identify errors in order to better manage the services\
    \ and infrastructure. To standardize the workflow with the operator dashboard\
    \ we aim to build an MVP for such an \u201COperator Dashboard\u201D. There will\
    \ be a view on the sensitive data archive that will provide Helpdesk with means\
    \ to identify issues such as number of submissions per user, failed submission\
    \ and the reason, or how many times a dataset has been accessed, accession identifiers\
    \ for datasets and their associated files etc.\nFor system admins the main objective\
    \ is to have means to trace errors and investigate failed submissions or to spot\
    \ issues related to downloading/accessing datasets/files. We also want to have\
    \ the ability to modify and retry failed jobs and make safe manual updates to\
    \ specific database fields.\n\nWe have not implemented any dashboard or control\
    \ interfaces before and we hope that by bringing this project to the hackathon\
    \ we can get input from people in different organizations on best practices for\
    \ design and what we might not have thought about for the dashboard."
  authors: Johan Viklund, Stefan Negru and Dimitrios Bampalikis
  expected_audience: 'Backend developers with a little familiarity with go

    Experience with docker and containers

    RabbitMQ, PostgrerSQL, S3

    Frontend developers'
  expected_outcomes: 'During hackathon

    * MVP of the dashboard

    * Display number of messages in each queue

    * Show where files are in the ingestion pipeline

    * How many files are in each inbox

    * Retry one submission job


    After:

    * Production use of dashboard for helpdesk staff to monitor submission of files
    - 6 months

    * Modification of job messages and retries of errors - 12 months'
  hacking_topic: 'Compute Platfrom

    Data Platform

    Federated Human Data'
  leads: johan.viklund@nbis.se
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/21
  number: '21'
  number_of_expected_hacking_days: '4'
  project_number: 21
  title: Operator dashboard for controlling the NeIC Sensitive Data Archive
- abstract: "This project will improve the integration of Plant data standards with\
    \ important interoperability technologies. Indeed, some interoperability technologies\
    \ have already been established with BrAPI, MIAPPE and ISA (Tab/JSON) for Phenotyping\
    \ data, but the link between phenotype and omics data needs to be improved. The\
    \ latter can rather be well described using bioschemas and therefore it will be\
    \ useful for plant researchers to build a graph dataset embedding both MIAPPE\
    \ and Bioschemas annotated data. We will enable plant researchers' friendly data\
    \ archive by embedding the main plant standards (MIAPPE, BrAPI, ISA) in RO Crate.\
    \ To link with the current activities of the plant communities, and to ease the\
    \ integration of more diverse data types, a bridge with Bioschemas will be set\
    \ up by finalizing the MIAPPE Bioschemas mapping initiated during the 2021 biohackathon.\
    \ To demonstrate the interest of this, real data will be converted from existing\
    \ sources (BrAPI, ISA Tab, MIAPPE databases) to RO Crate and Bioschemas to sketch\
    \ some proof-of-concept use case (eg, showing phenotyping network on a map, showing\
    \ the link between expression and phenotype data, \u2026)."
  authors: Cyril Pommier, Marco Brandizi, Philippe Rocca-Serra and Sebastian Beier
  expected_audience: "Experts critical for the success of the project:\nStian Soiland-Reyes\
    \ - The University of Manchester - soiland-reyes@manchester.ac.uk \nPhilippe Rocca-Serra\
    \ - Oxford e-Research Centre - philippe.rocca-serra@oerc.ox.ac.uk\n\nThe project\
    \ is open to any person that would like to join in this effort. We are especially\
    \ encouraging people familiar with RO Crate, Bioschemas, ISA."
  expected_outcomes: '1) Alignment of Bioschemas and MIAPPE, with a fully fledged
    how-to-use guide for embedding Bioschemas markup for MIAPPE compliant web resources

    2) RO Crate containing plant standards (MIAPPE, BrAPI, ISA (tab or JSON))

    3) Use case study with at least one dataset

    4) RO Crate fully usable by plant researchers for their data integration and exchange,
    including loading into visualization and analysis tools.

    5) RO Crate used for submission in data repositories such as dataverse.

    6) Documentation and training on the use of RO Crate

    7) Reviewed patterns allowed in RO (i.e. does RO work with ontology other than
    sdo),  and updates to API (RO-crate API, BRAPI (?) , ISA-API?)

    8) Eased knowledge extraction from plant integrative graph using tools such as
    Knetminer.'
  hacking_topic: 'Bioschemas

    Interoperability Platform

    Plant Sciences

    Tools Platform'
  leads: Cyril Pommier <cyril.pommier@inrae.fr> ; Marco Brandizi <marco.brandizi@rothamsted.ac.uk>
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/22
  number: '22'
  number_of_expected_hacking_days: '4'
  project_number: 22
  title: Plant data exchange and standard interoperability
- abstract: "Bioschemas provides a lightweight vocabulary for making the content of\
    \ Web pages machine processable. However, as shown in Project 29 at BioHackathon\
    \ 2021 (10.37044/osf.io/y6gbq), harvesting markup by visiting each page of a site\
    \ is not feasible for large sites due to the time required to process each page.\
    \ This approach imposes processing demands on the publisher and consumer. In February\
    \ 2022, the Schema.org community proposed a mechanism for sharing markup from\
    \ multiple pages as a DataFeed published at an established location. The feed\
    \ could be a single file with the whole content or split into multiple files based\
    \ on some aspect of the dataset, e.g. ChEMBL could have a file for proteins and\
    \ another one for molecular entities. This would reduce processing demands for\
    \ publishers and consumers and speed up data harvesting.\n\nThe aim of this hackathon\
    \ proposal is to explore the implementation of the Schema.org proposal from both\
    \ a producer and consumer perspective, for a variety of resources implementing\
    \ different Bioschemas profiles. Additionally, we will investigate whether existing\
    \ mechanisms such as OAI-PMH (https://www.openarchives.org/pmh/) or GraphQL (https://graphql.org/)\
    \ can be exploited to generate on-the-fly dumps of Bioschemas markup restricted\
    \ to a consumer\u2019s particular data need; rather than having to process a single\
    \ monolithic (possibly huge) file. On the consumer side, we will prototype a consumption\
    \ pipeline that enables these feeds to be ingested into knowledge graphs including\
    \ IDP Knowledge Graph (10.37044/osf.io/v3jct) and the Open AIRE Research Graph.\
    \ To enable the latter, we will also develop additional mappings between Bioschemas\
    \ profiles and OpenAIRE\u2019s data model. We will need to understand how to mix\
    \ schema feeds from different sources, possibly exploiting background knowledge\
    \ from Wikidata to reconcile concepts."
  authors: Alasdair Gray, Ivan Micetic and Alban Gaignard
  expected_audience: JSON-LD, Triplestores, Schema.org/Bioschemas, Knowledge Graphs,
    OAI-PMH, GraphQL, g2g
  expected_outcomes: '- Improved understanding of generating and publishing DataFeeds,
    including exploiting existing mechanisms to generate subsets of a data feed, guidelines
    for data producers to easily produce Bioschemas DataFeeds.


    - Prototype mechanism for producing, consuming and integrating multiple DataFeeds


    - Additional mappings between Bioschemas and OpenAIRE/Datacite


    - Tutorials detailing step-by-step guides for publishing and consuming DataFeeds'
  hacking_topic: 'Bioschemas

    Data Platform

    Interoperability Platform

    Intrinsically Disordered Community'
  leads: 'Alasdair Gray

    Alban Gaignard'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/23
  number: '23'
  number_of_expected_hacking_days: '4'
  project_number: 23
  title: Publishing and Consuming Schema.org DataFeeds
- abstract: 'Last year, during the Biohackathon 2021, under the project "FAIRX: Quantitative
    bias assessment in ELIXIR biomedical data resources", we assessed the partition
    of sex within two databases, EGA and dbGaP. The evolution of the project can be
    found in https://github.com/elixir-europe/biohackathon-projects-2021/tree/main/projects/35)
    with an article to be submitted for publication. Rather than analysing the available
    datasets, this time we concentrate on the scientific literature to uncover sex
    imbalance in the published research. We will leverage the EuroPMC repository (https://europepmc.org/)
    and their available API to access and mine the content of free-text articles published
    there.

    The end result would be an automated text parser to extract the mention of the
    sex in the reported information of preclinical and clinical studies if any and
    thus provide insights on the current state of sex imbalance in the research publications.

    The project will combine several strategies to ensure access to the data. First,
    it will concentrate on specific parts of the articles where data should be located
    (Material and methods, as well as additional files). We will prioritise article
    types of interest, such as publications linked to recent clinical trials and preclinical
    studies. We will also review the status of the policies and guidelines on sex
    disclosure in scientific publications adopted by the different journals (such
    as Key Resources Tables, STAR methods and SAGER guidelines). Recommendations for
    a fairer reporting of sex in scientific publications will be drawn from the analysis
    of the results, which will be presented in a form that is suitable for future
    publication.

    We would like to invite Aravind Venkatesan - Senior Data Scientist - EMBL-EBI.
    He is working on the data science side for the EuropePMC.'
  authors: Olivier Philippe and Blanca Calvo
  expected_audience: 'Researchers in social sciences with interests in biomedicine
    and technology

    Data scientists with strong analytical and statistical knowledge

    Biostatisticians with interests in bias and data mining

    Researchers and practitioners in academic or industrial fields devoted to social
    equity'
  expected_outcomes: 'Four outcomes for the weeks

    * Parsing the portion of the text provided by Europe PMC and automatically detecting
    sex reporting of samples and/or humans or animal models involved in the studies

    * Aggregating the metrics for the subset of journals used during the Biohackathon

    * Providing a report giving the state of the research

    * Extending the text analysis to include other variables such as the publisher,
    the type of publication, etc.


    Three long-term expected outcomes

    * Writing an article in line with the SAGER and KPR principles

    * Extending the sample detection to a larger subset

    * Developing a pipeline to be run daily/weekly on the EuroPMC to provide this
    information as a service (under their API service)'
  hacking_topic: 'Data Platform

    Federated Human Data

    Interoperability Platform

    Machine learning'
  leads: 'Olivier Philippe - olivier.philippe@bsc.es

    Blanca Calvo - bcalvo.bsc@gmail.com'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/24
  number: '24'
  number_of_expected_hacking_days: '4'
  project_number: 24
  title: Quantitative bias assessment in ELIXIR - EuropePMC biomedical publications
    resources
- abstract: 'The Tools Ecosystem is a centralized repository for the open and transparent
    exchange of metadata about software tools and services in Bioinformatics and Life
    Sciences.

    It serves as the foundation for the sustainability of the diverse Tools Platform
    services, and for the interoperability between all these essential services (bio.tools,
    BioContainers, OpenEBench, Bioconda, WorkflowHub, usegalaxy.eu) and related resources
    outside of the ELIXIR Tools Platform (e.g. Bioschemas).


    The goal of this project will be to cross-compare and analyze the metadata centralized
    in the Tools Ecosystem to maintain high quality descriptions. In order to achieve
    these goals we need to design tools and processes that detect curation bottlenecks,
    perform rigorous data cross-validation and generate detailed reporting about potential
    issues and actionable items.


    Multiple strategies will be explored:

    - Comparison of the functional profiles of bio.tools entries with the corresponding
    semantic constraints defined in EDAM. Develop software to identify and report
    on inconsistencies between resources.

    - Comparison of the metadata defining a software tool with the knowledge extracted
    from publications that cite it, as well as the workflows that use it.


    Beyond the immediate improvement of the metadata, we plan to use the results of
    these analyses in order to:

    - Automate relevant analyses using continuous integration mechanisms (extending
    previous and current work in EDAM and the Tools Ecosystem)

    - Improve curation user interfaces to reduce the risk of annotation errors.

    - Provide high quality functional tool profiles to be used in the context of workflow
    annotation


    Another important goal is to provide onboarding of and support for scientific
    communities joining the Biohackathon.


    Given the nature of the data we use in this project, we will be working in close
    collaboration with the project "Enhance RDM in Galaxy by utilizing RO-Crates",
    who will also be leveraging workflow and software metadata from the same resources.'
  authors: "Hans Ienasescu, Lucie Lamothe, Herv\xE9 M\xE9nager, Veit Schw\xE4mmle,\
    \ Stuart Owen, Alban Gaignard and Matus Kalas"
  expected_audience: '- Ontology specialists

    - Workflow specialists

    - Python programmers

    - Data analysts

    - Bioinformatics Software providers/packagers

    - Scientific community domain experts'
  expected_outcomes: "By the end of the BioHackathon week:\n- Results of the cross-analysis\
    \ of bioinformatics tools, highlighting potential inconsistencies or annotation\
    \ gaps between the different resources, and suggesting annotation improvements\
    \ (missing or more specific terms) for registry curators.  \n- Software code to\
    \ run the analyses mentioned\n- Prototypes for CI tasks that automate the analyses\n\
    - Initiate contact with scientific communities and perform actions to ensure future\
    \ onboarding and support (e.g. identify gaps and EDAM, bio.tools, WorkflowHub)\
    \ \n\nWithin 3 months of the end of the Biohackathon:\n- Production-ready code\
    \ and CI tasks automating the analyses to improve the monitoring of the Tools\
    \ Ecosystem\n- Improvements to the bio.tools curation UI, if analysis results\
    \ reveal that such modifications might help or improve the annotation quality.\n\
    - New concepts in EDAM, tools in bio.tools , workflows in WorkflowHub created\
    \ by the scientific communities"
  hacking_topic: 'Bioschemas

    Federated Human Data

    Galaxy

    Interoperability Platform

    Tools Platform'
  leads: 'Hans Ienasescu (haiiu@dtu.dk)

    Lucie Lamothe (lucie.lamothe@france-bioinformatique.fr)'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/25
  number: '25'
  number_of_expected_hacking_days: '4'
  project_number: 25
  title: Scientific and technical enhancement of bioinformatics software metadata
    using the Tools Ecosystem open infrastructure
- abstract: 'Chemicals are used everywhere, with people and the environment being
    exposed to potentially harmful substances. The identification of intrinsic properties
    of chemical substances is needed to protect human health and the environment,
    however many of these chemicals transform either in the environment or in our
    bodies, while defining chemicals with an unknown or variable composition, complex
    reaction products or biological materials (so-called UVCBs) are increasingly important.
    The composition of these UVCB chemicals (estimated to be 25-40 % of high use chemical
    registries) can be variable or difficult to define, which means that the exchange
    of data about these chemical substances between resources is fraught with difficulty
    due to a lack of standards and compatible approaches, confounding FAIRification
    of these entities. Difficulties arise in: understanding the potential toxicological
    effects of such materials; linking to known biochemical transformations (e.g.,
    found in Rhea); performing and interpreting metabolomics/exposomics experiments;
    data dissemination; data reuse; data workflows; and in formulating regulatory
    actions (e.g., under REACH). Several large projects funded by the European Union
    (e.g. CLP, NanoCommons, ZeroPM), as well as locally funded projects (e.g. VHP4Safety)
    try to address these issues, but desperately need these FAIR issues solved using
    cheminformatics approaches.


    The aim of this project is to gather a critical mass of key cheminformatics resources
    and representatives to work on tackling the challenges with UVCBs and chemical
    transformations/metabolism. Our project builds on several previous BioHackathon
    efforts:

    Better integration with knowledge from Wikidata (Project 32 BioHackathon 2021)

    Include super and substructure searching (Elixir Czech Republic Service IDSM)

    FAIR Identifier Mapping, leading to PubChemLite (Project 27 BioHackathon 2019)

    Create metabolic and adverse outcome pathway models, which link better to other
    databases (Project 32 BioHackathon 2021)

    Extension and Continuous Integration of Cheminformatics Resources and Applications
    (Project 13, BioHackathon 2020)'
  authors: Denise Slenter, Egon Willighagen, Evan Bolton, Emma Schymanski and Tomas
    Pluskal
  expected_audience: Knowledge of chemistry, biochemistry, and/or toxicology is wanted.
    Our tools work in various programming languages (Java, Groovy, Python, R), as
    well as having different ways to integrate data (API, SPARQL, graph databases).
    Last, data curation is of importance to us (which does not always require programming
    skills), as well as being able to link to other databases, so we also welcome
    participants who have knowledge in this area.
  expected_outcomes: "Improved handling of transformation product pairs and reactions\
    \ (Rhea/PubChem/NORMAN-SLE/WikiPathways)\nCheminformatics approaches for dealing\
    \ with UVCBs (MInChI, \u201CConcepts\u201D) including first applications and examples\n\
    Automated workflows for FAIR data deposition to PubChem, Rhea, WikiPathways and\
    \ other key resources"
  hacking_topic: 'Bioschemas

    Data Platform

    Interoperability Platform

    Metabolomics

    Tools Platform'
  leads: 'Tomas Pluskal: tomas.pluskal@uochb.cas.cz

    Denise Slenter: denise.slenter@maastrichtuniversity.nl'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/26
  number: '26'
  number_of_expected_hacking_days: '4'
  project_number: 26
  title: Shedding the light on unknown chemical substances
- abstract: 'Mobilizing data from data infrastructures to data deposition databases
    is an integral service that research data management (RDM) platforms could offer.
    However, brokering the heterogeneous mixture of scientific data requires systems
    that are compatible with the diverse (meta)data models of the different RDM platforms,
    and diverse submission routes of different target repositories.


    The metadata management platform DataHub, an instance of the FAIRDOM-SEEK software,
    uses the well-established (Investigation Study Assay) framework to describe metadata.


    This BioHackathon project will specifically focus on designing and implementing
    data brokering systems from DataHub, to ELIXIR Deposition Databases, starting
    with the European Nucleotide Archive (ENA). During this project we will establish
    which existing tools can be reused, which need to be adapted or whether new tools
    need to be developed for data brokering from DataHub.


    We aim to make brokering tools more flexible, to support researchers and data
    stewards with metadata collection. We will also focus on increasing the sustainability
    and reducing the burden of maintenance of the tools, trying to limit dependencies
    on static reference files and hard coded variables.


    The design and the implementation of tools during this project aim to provide
    easy to maintain and flexible solutions for data brokering that can be further
    developed to be applied to other data repositories, and other national or institutional
    data management platforms.


    Finally, describing and implementing models for brokering data to ELIXIR Deposition
    Databases in this way, is one aim of ELIXIR-Converge (2020-2023), in Task 1.2.'
  authors: "Flora D'Anna, Zahra Waheed, Rafael Andrade Buono, Vahid Kiani, Michael\
    \ Dondrup, Korbinian B\xF6sl, Dipayan Gupta, Tony Burdett, Guy Cochrane and Frederik\
    \ Coppens"
  expected_audience: 'Knowledge of: ISA model, ENA submission process, FAIRDOM-SEEK,
    coding skills- particularly Python, JSON and XML'
  expected_outcomes: "Expected outcomes for the week:\n\nUnblock content agnostic\
    \ conversion of ISA-JSON to ISA-Tab. \nDesign and/or expand a tool to convert\
    \ ISA-JSON to SRA xml schema with limited dependency on static configuration files\
    \ and hard coded variables.\nDesign and/or implement a system for automatic update\
    \ of configuration files needed to convert ISA-JSON to SRA xml schema, based on\
    \ changes of the SRA schema.\nDesign and/or implement a method to submit metadata\
    \ exported from DataHub (FAIRDOM-SEEK instance) in ISA-JSON format to ENA, including\
    \ proof of concept for conversion of metadata exported from DataHub in ISA-JSON\
    \ format to SRA xml schema.\nUnblock ISA-Tab to SRA xml schema conversion using\
    \ ISA tools or new solutions.\n\n\nLong-term expected outcomes and timeframe in\
    \ months:\n\nM3: Adoption into other tools exporting ISA-JSON/Tab.\nM6: Adoption\
    \ of the ISA/ENA converter into the toolchain used by different FAIRDOM SEEK instances.\n\
    M12: Extension to various other relevant target formats e.g. PRIDE-XML and PAGE-JSON\n\
    M18: Successful conversion of ISA-JSON/Tab to the appropriate ISA formatted files\
    \ required by each repository (BioSamples, BioStudies, Metabolights, ArrayExpress\
    \ and PRIDE). \nM24: Successful end-to-end brokering from national and institutional\
    \ data management platforms."
  hacking_topic: 'Data Platform

    Interoperability Platform

    Tools Platform'
  leads: 'Flora D''Anna = flora.danna90@gmail.com, flora.danna@psb.vib-ugent.be

    Zahra Waheed = zahra@ebi.ac.uk'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/27
  number: '27'
  number_of_expected_hacking_days: '4'
  project_number: 27
  title: Streamlining data brokering from RDM platforms to ELIXIR Repositories
- abstract: 'Computational pipelines have become ubiquitous in bioinformatics, with
    an increasing need for sharing them among researchers in portable formats like
    the Common Workflow Language (CWL) standard.


    Galaxy has been involved in the development of the CWL standard from the start,
    and native support for CWL in Galaxy has been developed in a fork of the Galaxy
    codebase created by John Chilton.


    The first four European BioHackathons allowed several different contributors to
    work together on this project and discuss with the wider communities. This resulted
    in major progress in the CWL support in Galaxy, and in large portions of the CWL
    branch of Galaxy making their way into the core repository. In particular, in
    the 2021 edition we refactored the code in the fork going from 1,245 files (+241,593
    lines of code) to just 92 files (+4,361 lines).


    An initial Galaxy implementation of a major feature of the v1.2 version of the
    CWL specification was developed during the 2020 BioHackathon Europe: conditional
    execution of a workflow step. We plan to finish this work and merge the pull request
    ( https://github.com/common-workflow-language/galaxy/pull/123 ) in the Galaxy
    fork.


    Other goals for the 2022 BioHackathon will be to fix the 12 remaining required
    CWL 1.2 conformance tests, work on the other open issues ( tracked at https://github.com/common-workflow-language/galaxy/issues
    ), and continue the merge of the separate CWL branch into the upstream Galaxy
    repository.'
  authors: Michael R. Crusoe, Nicola Soranzo, Marius van den Beek and John Chilton
  expected_audience: Software developers with either Python or Web Frontend development
    skills (especially JavaScript/Vue.js), with or without an initial experience of
    development in Galaxy and/or CWL.
  expected_outcomes: '- Complete the implementation of CWL 1.2 conditionals and workflow
    default files in Galaxy

    - Support for ResourceRequirement to specify computational resources needed by
    a tool

    - Mapping of data ontologies to Galaxy datatypes for better mixing of CWL and
    Galaxy pipelines

    - Fix remaining CWL conformance tests

    - Advance the merge of the separate branch into the upstream Galaxy repository
    to be part of future Galaxy releases'
  hacking_topic: 'Compute Platfrom

    Galaxy

    Interoperability Platform

    Tools Platform'
  leads: Michael R. Crusoe
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/28
  number: '28'
  number_of_expected_hacking_days: '4'
  project_number: 28
  title: Support for the Common Workflow Language standard version 1.2 in Galaxy
- abstract: 'Human data is subject to ethical, legal, and sociological issues (ELSI),
    e.g. EU General Data

    Protection Regulations (GDPR), imposing restrictions on the data access and mobilisation.

    These genomic and phenotypic datasets are required to improve the understanding
    of the

    genetic basis of disease, supporting the delivery of personalised medicine to
    patients.

    This project links work in the ELIXIR Compute and Tools platforms with requirements
    from the

    Federated Human Data and Rare Diseases communities to build, validate, and deploy
    data

    analysis workflows across federated secure computational facilities, driven by
    1+MG use

    cases.

    The WfExS-backend (https://github.com/inab/WfExS-backend) is a high-level workflow

    execution software, fetching and materialising all elements needed to run a workflow:
    the

    workflow, engine, software containers and inputs. It creates and consumes RO-Crates,

    focusing on the interconnection of research infrastructures for handling sensitive
    human data.

    WfExS delegates workflow execution to existing workflow engines (Nextflow and
    cwltool) and

    is designed to facilitate secure and reproducible executions to promote analysis
    reproducibility

    and replicability. Secure executions are achieved using FUSE encrypted directories
    for

    non-disclosable inputs, intermediate results and output files.

    RO-Crate representations of workflow executions are an element of knowledge transfer

    between repeated executions. WfExS-backend stores all the gathered execution details,

    output metadata and execution provenance in the output RO-Crate achieving reproducible

    executions. Execution results are encrypted with crypt4gh and safely moved outside
    the

    execution environments.

    Documentation and demonstration of these tools, utilising synthetic data, to the
    human data

    communities (HDCs), while bringing HDCs feedback to the compute and tools platform

    facilitates uptake of these standards supporting interoperability.

    Future developments focus on: secure data export procedures; supporting 1+MG use
    cases

    and genomics infrastructure; supporting other workflow engines, e.g. SnakeMake
    and Galaxy;

    supporting other containerisation technologies; supporting additional secure execution

    scenarios; supporting additional workflows and data providers.'
  authors: "Dylan Spalding, Jos\xE9 M\xAA Fern\xE1ndez, Laura Rodr\xEDguez-Navas and\
    \ Salvador Capella-Guti\xE9rrez"
  expected_audience: 'People with snakemake or planemo / Galaxy experience.

    People with interesting Nextflow, CWL, snakemake or other workflows, hopefully
    already

    available in a git repository.

    People with interesting use cases, such as 1+MG use case experts or representatives
    from

    FHD or RD communities, with existing or developing workflows which can be described
    in a

    workflow language, where the inputs are available through permanent identifiers,
    and those

    inputs can be fetched, either openly or through authentication.

    Members or representatives of the compute and tools platforms, and federated human
    data

    community.'
  expected_outcomes: '1. Giving WfExS-backend a wider end user and developer base,
    and supporting the 1+MG

    use cases, including a draft container / workflow or recipe and associated documentation.

    2. Gap analysis identifying tools and services that are required, and adding support
    to

    additional workflow execution engines.

    3. Testing WfExS-backend in additional workflow execution scenarios.

    4. Improving generated Workflow Execution RO-Crate'
  hacking_topic: 'Compute Platform, Federated Human Data, Interoperability Platform,
    Rare Disease, Tools

    Platform, SW Containers, Benchmarking'
  leads: "Dylan Spalding dylan.spalding@csc.fi\nJos\xE9 M\xAA Fern\xE1ndez (jose.m.fernandez@bsc.es)\n\
    Laura Rodr\xEDguez-Navas (laura.rodriguez@bsc.es)"
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/29
  number: '29'
  number_of_expected_hacking_days: '4'
  project_number: 29
  title: Supporting federated secure workflows and analysis using WfExS-backend
- abstract: 'The Global Alliance for Genomics and Health (GA4GH), an international
    standard-setting organization bringing together opinion leaders in academia and
    industry, has proposed a set of community standards for data storage, transfer
    and processing in the cloud. The ELIXIR Cloud & AAI community, a GA4GH Driver
    Project, is developing the ELIXIR::GA4GH Cloud (EGC), a federated cloud environment
    for large-scale data analysis in the life sciences. Interoperability across services
    and clouds is achieved through adopting GA4GH standards and authentication and
    authorization guidelines.


    We have recently set up a service registry as an entry point into the EGC. Registered
    services have been tested for interoperability with one another and are deployed
    across various ELIXIR nodes. They can be used by our driver projects and other
    interested parties to run data analysis workflows of various types (e.g., CWL,
    Nextflow, Snakemake). The main goals of the hackathon project are to engage additional
    drivers/testers, systems/service administrators and service developers in the
    ELIXIR community to work on use cases, expansion of the EGC and further adoption
    of standards.'
  authors: Alexander Kanitz, Jonathan Tedds and Alvaro Gonzalez
  expected_audience: '- Bioinformaticians / data scientists, particularly those needing
    to run different workflows on large amounts of data

    - Systems/service administrators / DevOps, particularly those interested in having
    their nodes join the EGC

    - Developers, particularly those interested in adopting standards and guidelines
    to make their services compatible with the EGC'
  expected_outcomes: 'Possible outcomes include:

    - New driver projects found and/or use cases for the EGC defined

    - Additional computing centers and data portals represented by the BioHackathon
    - community integrated into the EGC

    - New services integrated into the EGC

    - Improved deployment documentation and automation (e.g., CI/CD)'
  hacking_topic: 'Compute Platfrom

    Containers

    GA4GH partnership

    Galaxy

    Tools Platform'
  leads: Alex Kanitz <alexander.kanitz@unibas.ch>
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/30
  number: '30'
  number_of_expected_hacking_days: '4'
  project_number: 30
  title: The ELIXIR::GA4GH Cloud - Admin and User Engagement
- abstract: 'This project aims to enhance the interoperability between the RDMkit
    and FAIR Cookbook. We will start by identifying gaps in the connection between
    the two resources, then build on previous technical linking solutions to implement
    lightweight, sustainable linking mechanisms. We will define and implement a combination
    of technical and operational procedures to ensure linking between the two resources
    evolves correctly with the addition, removal and updating of content, while keeping
    human involvement as minimal as possible.

    Where appropriate, we will also work on the content of the two resources in order
    to foster greater interoperability. We aim to identify areas of need in the two
    resources through both the aforementioned gap analysis and through exploratory
    user feedback at the Biohackathon. Based on this feedback, we will then implement
    an action plan to recruit targeted contributions to fill gaps and improve the
    interoperability between the resources without duplicating efforts.'
  authors: Rafael Andrade Buono and Danielle Welter
  expected_audience: 'Members of the editorial teams of RDMkit and FAIR Cookbook

    People with knowledge on RDMkit and FAIR Cookbook

    People with general interest in research data management and FAIR practices


    The knowledge and technical skills of the following are critical to the project:

    - Bert Droesbeke - VIB-Ugent / ELIXIR-BE - bert.droesbeke@psb.vib-ugent.be

    - Philippe Rocca-Serra - University of Oxford - philippe.rocca-serra@oerc.ox.ac.uk'
  expected_outcomes: 'At the end of the BioHackathon:

    -A gap analysis of the connections of the two resources, including identification
    of content gaps where connections could be beneficial

    -An improvement on the connections, with addition of mechanisms (technical and
    operational) to help editors identify and deal with:

    --Broken links in content and connected resources

    --Highlighting of content that might be going stale or getting outdated, and require
    review

    --Flagging of content that has been heavily edited by a connected resource, thus
    potentially requiring addition or removal of links


    After the BioHackathon (6 months):

    -New content based on identified gaps and contributors

    -Enhanced interoperability between RDMkit and FAIR Cookbook with more and better
    links

    -Implementation of maintenance tasks in both resources triggering actions from
    the editorial teams in support of long term sustainability'
  hacking_topic: 'Data Platform

    Interoperability Platform

    Tools Platform

    Training Platform'
  leads: 'Rafael Andrade Buono - rafael.buono@psb.ugent.be (Primary lead)

    Danielle Welter - danielle.welter@uni.lu'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/31
  number: '31'
  number_of_expected_hacking_days: '4'
  project_number: 31
  title: 'The What & How in data management: Improving connectivity between RDMkit
    and FAIR Cookbook'
- abstract: "This Training booster project has two components: 1) applying and assessing\
    \ the ELIXIR-GOBLET lesson on how to develop FAIR training materials, and 2) implementing\
    \ and evaluating a step-by-step protocol to create learning paths via a case study\
    \ approach. The BH2022 participants will have the choice to hack on any of the\
    \ two components or even both.\n\nComponent 1: A hands-on lesson on how to FAIRify\
    \ training materials was designed and initially created in 2021 during ELIXIR\
    \ hackathons, including the BH2021. Since then, the lesson is being developed\
    \ and will be finalised by October 2022, in time to be presented at the GOBLET\
    \ AGM 2022. The goal of this project\u2019s component is to apply the lesson to\
    \ actual training materials from ELIXIR Communities and training providers, assess\
    \ its effectiveness and integrate into the lesson the feedback received from the\
    \ GOBLET AGM 2022.  \n\nComponent 2: The Learning Path step-by-step protocol also\
    \ started as a project in the BH2021. The protocol is agnostic to the scientific\
    \ field and is accompanied by guidelines to best support curriculum developers\
    \ and trainers in designing efficient learning paths. The goal of the component\
    \ is to apply the developed protocol to actual training materials from ELIXIR\
    \ Communities, thus implementing it and assessing its effectiveness. The BH2022\
    \ participants will bring along their case studies (courses, materials, modules\
    \ etc.) to build a \u2018minimal viable product (MVP)\u2019 version of their own\
    \ case study\u2019s learning path.  \n\nAn example could be a learning path for\
    \ data stewards training, locating tasks, responsibilities, and competencies required\
    \ for the job. A second example could be for the emerging Systems Biology ELIXIR\
    \ Community, where learning paths are to be built (separate BH proposal), or other\
    \ ELIXIR Communities with the need to structure their training resources into\
    \ learning paths. "
  authors: Patricia Palagi (ELIXIR-CH),  Mijke Jetten (ELIXIR-NL), Allegra Via (ELIXIR-IT),
    Loredana Le Pera (ELIXIR-IT), Celia van Gelder (ELIXIR-NL), Alexia Cardona (ELIXIR-UK),
    Melissa Burke (Australian BioCommons), Jessica Lindvall (ELIXIR-SE).
  expected_audience: "Experience in providing training\nExperience in training material\
    \ development and delivery\nExperience in FAIR data and/or FAIR training\nHave\
    \ training materials that you wish to FAIRify \nData stewards"
  expected_outcomes: "Feedback on the effectiveness of the FAIR training material\
    \ lesson\nSets of FAIRified training materials  from ELIXIR Communities\nA plan\
    \ to improve  the FAIR training material lesson according to the feedback received\n\
    Collection of feedback on the application of the Learning Path protocol (pitfalls\
    \ and exceptions)\nEvaluated version 1.0 of the BH2021 Learning Path step-by-step\
    \ protocol \nMVP learning paths for 2-3 case studies"
  hacking_topic: Training, FAIR principles, FAIR training materials, Bring your own
    training materials, Learning path, curriculum design, KSAs, learning outcomes,
    implementation
  leads: Patricia Palagi (ELIXIR-CH) - patricia.palagi@sib.swiss & Mijke Jetten (ELIXIR-NL)
    - mijke.jetten@dtls.nl
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/32
  number: '32'
  number_of_expected_hacking_days: '4'
  project_number: 32
  title: 'Training booster: developing FAIR training materials and Learning Paths'
- abstract: "Systems biology is an important area for ELIXIR, as illustrated by the\
    \ emergence of the Systems Biology Community. Building on Project 9 from last\
    \ year\u2019s BioHackathon, and in collaboration with the ELIXIR\u2019s Biocuration\
    \ Focus Group and Training Platform, we aim to develop a learning path for systems\
    \ biology biocurators (https://github.com/elixir-europe/biohackathon-projects-2021/tree/main/projects/9).\
    \ This will support the creation and curation of interoperable and reusable models\
    \ for precise hypotheses and predictions.\n\nTo this end, we will produce an overview\
    \ of systems biology courses and training materials, and organize them in an ELIXIR\
    \ TeSS Collection (https://tess.elixir-europe.org/collections). In this process,\
    \ we will also identify training gaps and propose learning objectives to ensure\
    \ the development of necessary competences.\n\nLearning paths require a \u2018\
    roadmap\u2019 for training units and modules (https://en.wikipedia.org/wiki/Learning_pathway).\
    \ By reviewing the existing materials in the domains of knowledge annotation,\
    \ diagrammatic representation and model building, we will catalog and harmonise\
    \ available guidelines and training materials, exploring the following areas:\n\
    \n-how to annotate and encode bioentities and molecular interactions, building\
    \ on experience of the Biocuration Focus Group and existing content for resources\
    \ like UniProt, IMEx or MI2CAST;\n\n-how to create systems biology diagrams, with\
    \ emphasis on visual exploration and analytics, benefiting from experience of\
    \ Reactome, WikiPathways and Disease Maps Community;\n\n-how to enrich curated\
    \ knowledge with text mining, benefiting from the development of the ELIXIR Data\
    \ Platform literature annotation services and its Implementation Study on Scalable\
    \ Curation;\n\n-how to build systems biology models for analysis and simulations,\
    \ in relation to BioModels, SABIO-RK and other resources for interoperable and\
    \ reproducible models.\n\nFor all the topics above, we will evaluate available\
    \ materials on relevant interdisciplinary aspects, in particular on FAIR principles\
    \ and data management, such as RDMTollkit, and incorporate those with suitable\
    \ coverage."
  authors: Marek Ostaszewski, Mihail Anton and Luana Licata
  expected_audience: '- Biocuration of molecular knowledge (entities and their interactions)

    - Tools and standards for model building

    - Graphical representation of biological models

    - Web services and platforms for sharing models and annotations

    - Learning paths methodology'
  expected_outcomes: '- A publication draft by mid 2023, deposited on biorxiv

    - Necessary materials required for the deposition learning path for systems biology
    biocuration in a platform like TeSS

    - One or several ELIXIR TeSS collections of training materials

    - A comprehensive report of the systems biology curation areas in need of development
    of training materials'
  hacking_topic: 'Data Platform

    Tools Platform

    Training Platform'
  leads: Marek Ostaszewski, marek.ostaszewski@uni.lu
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/33
  number: '33'
  number_of_expected_hacking_days: '4'
  project_number: 33
  title: Training Systems biology curators in building interoperable and reusable
    models following a learning path approach
- abstract: "In previous hackathons (Biohackathon 2021, Bringing Genomic Data to the\
    \ Clinic 2022), we have created a proof of concept tool that indicates confidence\
    \ in colorectal cancer subtyping given various single and multi-omic methods,\
    \ and is further able to indicate specific compounds for precise pharmacological\
    \ intervention given an individual\u2019s transcriptome once subtype is established,\
    \ heavily leveraging the Drugmonizome tool (Ma\u2019ayan lab, MSSM). We will build\
    \ a validation engine that uses federated public datasets, as well as data from\
    \ a number of health systems, to calculate the potential efficacy of compounds\
    \ given longitudinal effects of treatment within a particular disease subtype.\
    \ PRIDE, CPTAC, Massive, and other datasets will be used in conjunction with genomic\
    \ data to validate protein and pathway targets, looking specifically at subtype-relevant\
    \ pathways pre- and post- treatment. To calculate clinical effectiveness in populations,\
    \ meta-analysis of retrospective studies (example links below) of EMA, FDA and\
    \ other national agency (e.g. Japan) approved drugs will be harmonized to the\
    \ MCBS scale. We will then attempt to define likelihood of drug subtype efficacy\
    \ combining proteome and global efficacy data, presenting summarized data in a\
    \ web app (likely shiny). Our stretch goal will be to present a pathway for working\
    \ \u201Cbackward\u201D along these lines (e.g. defining clinical subtypes given\
    \ pharmacological effectiveness). This is of critical importance due to the lack\
    \ of subtyping for many prevalent diseases, e.g. most forms of dementia.\n\nExample\
    \ publications for meta-analysis\nhttps://www.bmj.com/content/359/bmj.j4530\n\
    https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2733563\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3679802/"
  authors: Ben Busby, Hyonyoung Shin, Emerson Huitt, Jedrez Kubica and Ted Laderas
  expected_audience: The five folks above have agreed to work on this, and at least
    2-3 of us expect to be on site.  Experience in cancer pharmacology, metadata harmonization,
    information theory, or proteomics especially welcome, if other folks are interested
    in this problem!
  expected_outcomes: "Dockerized container for with tools that \n+indicate potential\
    \ treatments\n+present an aggregate validation score for multiomic and clinical\
    \ data-based approaches\n+present individual scores and other information"
  hacking_topic: 'Cancer

    Federated Human Data

    industry

    Proteomics'
  leads: Ben Busby bbusby@dnanexus.com
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/34
  number: '34'
  number_of_expected_hacking_days: '4'
  project_number: 34
  title: Using Federated Public Data for Disease Subtyping and Prediction of Effective
    Treatments
- abstract: 'The explosion of the amount of biological data and the rise of cloud
    computing have been increasing the demand for distributed data analysis. GA4GH
    Cloud Workstream has developed the Workflow Execution Service (WES) Standard,
    which helps realize "Bring workflow to data."


    To support researchers to utilize the published workflow resources, we developed
    Sapporo, a production-ready implementation of the WES. Sapporo is a unique WES
    implementation that supports multiple workflow languages. The DDBJ Center, a counterpart
    of NCBI and EBI in Japan, provides Sapporo-based WES to researchers in Japan.
    In the past BioHackathon Europe, we could solve the interoperability issues of
    Sapporo with Elixir WES. Improvements in various WES implementations will make
    it easier to share and perform data analysis across organizations and countries.


    However, there are unsolved issues in the quality control of shared workflows,
    which causes problems to the operation of WES. The workflow quality includes;
    the correctness of workflow language syntax, test details, and sufficiency of
    workflow metadata, such as license, version, and maintainers. In many public workflow
    registries, quality control of registered workflows depends on the registry maintainers,
    which undermines the scalability of the registry. Therefore, we developed Yevis,
    a TRS-compatible and GitHub-based system that supports building a registry with
    automated quality control. Yevis uses Sapporo as an on-demand instance to run
    workflow testing, which assures the portability of the testing environment.


    In BioHackathon Europe 2022, we aim to extend the functionalities of Yevis and
    Sapporo to help the quality control of the existing workflow registries, such
    as WorkflowHub. We also would like to welcome new contributors and get feedback
    on the products from the BioHackathon participants. By collaborating with the
    other BioHackathon participants, we would like to contribute to promoting the
    publication of well-maintained workflows.'
  authors: Tazro Ohta, Hirotaka Suetake, Tomoya Tanjo, Manabu Ishii and Bruno Kinoshita
  expected_audience: 'Workflow composers (who write workflow language)

    Workflow platform developers (who develop workflow language and runtime)

    Workflow registry maintainers

    On-premise/Cloud infrastructure administrators'
  expected_outcomes: 'The community consensus on quality validation criteria of published
    workflows

    The systematic method to automatically validate published workflows by WES

    Public workflows verified by the system

    More participants familiar with WES and other cloud workflow solutions

    Novel collaboration network between the workflow users and the developers'
  hacking_topic: 'Compute Platfrom

    GA4GH partnership

    Tools Platform'
  leads: 'Tazro Ohta t.ohta@dbcls.rois.ac.jp

    Hirotaka Suetake suehiro619@gmail.com'
  link: https://github.com/elixir-europe/bioHackathon-projects-2022/tree/master/projects/35
  number: '35'
  number_of_expected_hacking_days: '4'
  project_number: 35
  title: Workflow Execution Service to help the quality improvement of published workflows
---